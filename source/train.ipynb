{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "from model import *\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512\n",
    "number_of_conv = 5\n",
    "encoder_filters = 512\n",
    "kernel_size =  5\n",
    "encoder_rnn_unit = 256\n",
    "zoneout = 0.1\n",
    "dropout_rate = 0.5\n",
    "\n",
    "prenet_dim = 256\n",
    "n_mel_channels = 80\n",
    "decoder_rnn_unit = 1024\n",
    "linear_unit = n_mel_channels\n",
    "attention_location_filters = 32\n",
    "attention_dim = 128\n",
    "attention_kernel_size = 34\n",
    "\n",
    "postnet_embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = ['./text/' + file_name for file_name in os.listdir('./text/')]\n",
    "wav_file = ['./wav/' + file_name for file_name in os.listdir('./wav/')]\n",
    "gate_file = ['./gate/' + file_name for file_name in os.listdir('./gate/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 699.24it/s]\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "wav = []\n",
    "gate = []\n",
    "for text_fn, wav_fn, gate_fn in tqdm(zip(text_file[:100], wav_file[:100], gate_file[:100])):\n",
    "    with open(text_fn, 'rb') as f:\n",
    "        text.append(pkl.load(f))\n",
    "    with open(wav_fn, 'rb') as f:\n",
    "        wav.append(pkl.load(f).T)\n",
    "    with open(gate_fn, 'rb') as f:\n",
    "        gate.append(pkl.load(f))\n",
    "        \n",
    "with open('./vocab.pkl', 'rb') as f:\n",
    "    vocab = pkl.load(f)\n",
    "    \n",
    "text = np.array(text)\n",
    "wav = np.array(wav)\n",
    "gate = np.array(gate)\n",
    "inp_vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 810, 80)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, dev_input, train_mel, dev_mel = train_test_split(text, wav, test_size = 0.1, random_state = 255)\n",
    "train_gate, dev_gate = train_test_split(gate, test_size = 0.1, random_state = 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 187) (10, 187)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape, dev_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "def mean_abs_error(x,y):\n",
    "    '''\n",
    "    x : model's predictions (B, T)\n",
    "    y : label mel output (B, T)\n",
    "    '''\n",
    "    return tf.reduce_mean(tf.abs(x-y))\n",
    "gate_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def loss_function(pred, target):\n",
    "    mel_output, post_mel_output, pred_gate = pred\n",
    "    mel_target, target_gate = target\n",
    "    \n",
    "    mae = mean_abs_error(mel_output, mel_target) + mean_abs_error(post_mel_output, mel_target)\n",
    "    bloss =  tf.cast(gate_loss(pred_gate, target_gate), tf.float32)\n",
    "    return mae + bloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_abs_error(tf.zeros((128,32,128)), tf.ones((128,32,128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_vocab_size = inp_vocab_size,\n",
    "                  embedding_dim = embedding_dim,\n",
    "                  num_of_conv_layer = number_of_conv,\n",
    "                  filters = encoder_filters,\n",
    "                  kernel_size = kernel_size,\n",
    "                  rnn_unit = encoder_rnn_unit,\n",
    "                  zoneout_prob = zoneout,\n",
    "                  dropout_rate = dropout_rate)\n",
    "\n",
    "decoder = Decoder(prenet_dim1 = prenet_dim, \n",
    "                  prenet_dim2 = prenet_dim, \n",
    "                  n_mel_channels = n_mel_channels, \n",
    "                  rnn_unit = decoder_rnn_unit, \n",
    "                  linear_unit = linear_unit, \n",
    "                  attention_location_filters = attention_location_filters, \n",
    "                  attention_dim = attention_dim, \n",
    "                  attention_loc_kernel_size = attention_kernel_size, \n",
    "                  dropout=dropout_rate)\n",
    "\n",
    "postnet = PostNet(n_mel_channels=n_mel_channels,\n",
    "                 postnet_embedding_dim = postnet_embedding_dim,\n",
    "                 kernel_size = kernel_size,\n",
    "                 dropout_rate = dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder,\n",
    "                                 postnet = postnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch_input, batch_target, batch_gate, encoder_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output = encoder(batch_input, encoder_hidden)\n",
    "        print(enc_output.shape)\n",
    "        lstm1_hidden, lstm2_hidden = decoder.get_initialize(batch_target.shape[0])\n",
    "        \n",
    "        dec_input = tf.zeros((batch_target.shape[0], 1, batch_target.shape[-1]), tf.float32)\n",
    "        attention_weights_cum = tf.zeros((batch_target.shape[0], batch_input.shape[1]))\n",
    "        # initialize attention weights cum (batch_size, encoder_output_length)\n",
    "        print(attention_weights_cum.shape)\n",
    "        gate_output = []\n",
    "        mel_output = []\n",
    "        for i in range(batch_target.shape[1]-1):\n",
    "            dec_input, stop_token_pred, lstm1_hidden, lstm2_hidden, attention_weights = decoder(dec_input,\n",
    "                                                                             enc_output,\n",
    "                                                                             lstm1_hidden,\n",
    "                                                                             lstm2_hidden,\n",
    "                                                                             attention_weights_cum)\n",
    "            attention_weights_cum += attention_weights # attention culmulative\n",
    "            gate_output.append(stop_token_pred)\n",
    "            mel_output.append(dec_input)\n",
    "            dec_input = tf.expand_dims(batch_target[:,i,:], 1) # new input of mel spectrogram (Batch_size, 1, mel_spectrogram dim)\n",
    "        mel_output = tf.stack(mel_output, axis = 1)\n",
    "        mel_output = tf.reshape(mel_output, (mel_output.shape[0], -1, mel_output.shape[-1]))\n",
    "        # mel_output : mel_spectrogram (batch_size, mel_spectrogram(time dim), mel_spectrogram(mel dim))\n",
    "        gate_output = tf.stack(gate_output, axis = -1)\n",
    "        gate_output = tf.reshape(gate_output, (gate_output.shape[0], -1))\n",
    "        # gate_output : stop token prediction : (batch_size, mel_spectrogram(time dim))\n",
    "        print('mel_output :',mel_output.shape)\n",
    "        print('gate_output :',gate_output.shape)\n",
    "        postnet_output = postnet(mel_output)\n",
    "        loss += loss_function(pred = (mel_output, postnet_output, gate_output),\n",
    "                              target = (batch_target[:,:-1, :], batch_gate[...,:-1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    \n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 187, 512)\n",
      "(10, 187)\n",
      "mel_output : (10, 809, 80)\n",
      "gate_output : (10, 809)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.46722493>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step(tf.convert_to_tensor(train_input[:10]), \n",
    "           tf.convert_to_tensor(train_mel[:10]), \n",
    "           tf.convert_to_tensor(train_gate[:10]), encoder.get_initialization(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
